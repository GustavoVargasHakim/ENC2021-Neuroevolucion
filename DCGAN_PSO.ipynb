{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN-PSO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab2d4a6bce654cd390985be3b86e4d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bfa08350d5644d748261645a956fb096",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_049df5f3733b453e8b67e4f7ab3725a8",
              "IPY_MODEL_11d387f49a90472291c8b43347b83984"
            ]
          }
        },
        "bfa08350d5644d748261645a956fb096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "049df5f3733b453e8b67e4f7ab3725a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7014ed11cc34bd3a860ce47791ce686",
            "_dom_classes": [],
            "description": "  8%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 762880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df75e42d96194dfe8f8475581bc601f9"
          }
        },
        "11d387f49a90472291c8b43347b83984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eef05689cbfc4c5f9ff969632893dad6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 762880/9912422 [00:21&lt;04:45, 32018.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a3e834d31cd4fb5badd0c5755296bec"
          }
        },
        "b7014ed11cc34bd3a860ce47791ce686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df75e42d96194dfe8f8475581bc601f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eef05689cbfc4c5f9ff969632893dad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a3e834d31cd4fb5badd0c5755296bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na7s6VHkKLdA"
      },
      "source": [
        "# **DCGAN-PSO**\n",
        "\n",
        "Es un algoritmo de **neuroevolución** encargado de diseñar y entrenar Redes Generativas Adversarias (**GANs**).\n",
        "Esta basado en un algoritmo de Inteligencia Colectiva (rama del Cómputo Evolutivo) conocido como Optimización por Cúmulo de Partículas (**PSO**).\n",
        "\n",
        "A través de la evolución de una población (**Enjambre**) de arquitecturas de GAN (**Partículas**) se obtiene una GAN entrenada progresivamente escalando su resolución para realizar un entrenamiento menos complejo y, por lo tanto, más estable para la GAN. Se tomo como idea central lo desarrollado en (Karas et al. 2017).\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=189XM7ucvHRGS3_sp-eU0hXqLPzLioX9n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmiJpzgjMF9k"
      },
      "source": [
        "## **Tipo de Neuroevolución**\n",
        "\n",
        "El diseño de la **arquitectura** de las GANs es completamente evolucionado mediante el **PSO**, mientras que su **entrenamiento** progresivo se realiza mediante **retropropagación**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1JJAZRvCl410ePMvTSUEuC4qriglnJZwA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO4Zxa6LQmn9"
      },
      "source": [
        "## **Codificación**\n",
        "La codificación de la arquitectura de las GANs es **directa** mediante una **lista**. Cada módulo representa un **tipo de capa** y los **hiperparámetros** evolucionables. Mediante una sola lista se decodifica la arquitectura del **Generador** y el **Discriminador**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1KXLe75_-10TxTh3FuDhtb03O19bR1HIy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9NV4_GURSHM"
      },
      "source": [
        "## **Optimización por Cúmulo de Partículas (PSO)**\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=1kE3rl-QvPZgKDMuVwOaX_bVjgBrKZgMb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhcOUTKuRxPL"
      },
      "source": [
        "## **Operadores de evolución**\n",
        "* Se utilizan un operador especial para obtener un **vector de diferencias** entre dos partículas.\n",
        "![picture](https://drive.google.com/uc?export=view&id=17hHBzuuUVkK7ES-uWOVL7FA6z3WOnUUk)\n",
        "\n",
        "\n",
        "* Se utilizan operadores para **actualizar** la **velocidad** y **posición** de la partícula.\n",
        "![picture](https://drive.google.com/uc?export=view&id=16DYA13jIMUnPRlDpUEeqHWAW-B9p4jw7)\n",
        "\n",
        "Estos operadores se tomaron y adaptaron de un algoritmo de neuroevolución para redes neuronales convolucionales (Junior y Jen, 2019)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMf540TQjZQr"
      },
      "source": [
        "## **Aptitud**\n",
        "La aptitud de cada partícula decodificada y entrenada se mide utilizando lotes de imágenes sintéticas obtenidas del generador para calcular la Fréchet Inception Distance (**FID**), diseñada para evaluar a las GANs(Heusel et al. 2017). Esta medida utiliza la CNN **Inception v3** para obtener los vectores de características (**2048** valores númericos) del lote de imágenes sintéticas y un lote del mismo tamaño de imágenes reales, con ello se evalua la diferencia entre ambas distribuciones de datos. Entre menor sea este valor, mayor similitud hay entre ambos lotes de imágenes, siendo cero cuando son exactamente iguales.\n",
        "![picture](https://drive.google.com/uc?export=view&id=1tA4WrnjF3HH6WiWf71-W6MEf5jmo4_s1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuKK-WYfSg1n"
      },
      "source": [
        "## **Resultados**\n",
        "Se utilizaron **radiografías de toráx** de pacientes con **COVID-19**. Se escaló de una resolución de **4x4** a **256x256** píxeles. Se realizó la medición mediante la métrica Fréchet Inception Distance (**FID**).\n",
        "Animación con la evolución de las DCGAN: https://drive.google.com/file/d/1-rUoJldZSj2wx47H9-3QSojUn3oKscHd/view\n",
        "![picture](https://drive.google.com/uc?export=view&id=11mst8TCChPUP8D1SFA1VHlGcXzB3syxA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z17aNSSTk2l"
      },
      "source": [
        "## **Artículo DCGAN-PSO**\n",
        "Juan-Antonio Rodríguez-de-la-Cruz, Héctor-Gabriel Acosta-Mesa and Efrén Mezura-Montes, **Evolution of Generative Adversarial Networks using PSO for Synthesis of COVID-19 Chest X-Ray Images**, in Proceedings of the IEEE Congress on Evolutionary Computation, Krakow, Poland, IEEE Press, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaLLRoTUUFwV"
      },
      "source": [
        "## **Referencias**\n",
        "* Karras, T., Aila, T., Laine, S., & Lehtinen, J. (2017). Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196.\n",
        "* Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2017). Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30.\n",
        "* Junior, F. E. F., & Yen, G. G. (2019). Particle swarm optimization of deep neural networks architectures for image classification. Swarm and Evolutionary Computation, 49, 62-74.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdR-PbyaMwdK"
      },
      "source": [
        "### **Cargar librerías**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNAhJiW_0ea5"
      },
      "source": [
        "#Librerías PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torchsummary import summary\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision\n",
        "\n",
        "#Librería para graficar\n",
        "import matplotlib.pyplot as plt\n",
        "#Librerías misceláneas\n",
        "% matplotlib inline\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from IPython import display\n",
        "\n",
        "#Librería Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython import display\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "#Librerías para calcular FID\n",
        "import scipy\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udL_VO2fMflc"
      },
      "source": [
        "### **Parámetros del algoritmo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3YaAmnr0pj1"
      },
      "source": [
        "####PARÁMETROS A CAMBIAR PARA EXPERIMENTAR####\n",
        "tamaño_lote = 128 #Definir el tamaño de lote de acuerdo a la resolución actual\n",
        "num_particulas  = 10  #N° de partíiculas en el enjambre\n",
        "num_generaciones = 10  #Número de generaciones por cada resolución\n",
        "Cg = 0.5  #Parámetro Cg\n",
        "num_epocas = 15 #Número de épocas para entrenar cada partícula\n",
        "tamaño_dataset = 10000 #Número de imágenes utilizadas en los conjuntos de entrenamiento. Máximo 60,000.\n",
        "tamaño_comparar = 400 #N° de imágenes a comparar cuando se calcula el FID. Máximo 60,000.\n",
        "#Parámetros para conocer en qué resolución comienza y hasta qué resolución evoluciona\n",
        "resolucion_inicial = 4 #Resolución de la imagen creada por la primera capa Fully Connected. \n",
        "resolucion_actual = 32 #Resolución que se busca obtener\n",
        "#Número de capas transpuestas que duplican la resolución de las creaciones\n",
        "num_max_capas_T = int(np.log(resolucion_actual/resolucion_inicial)/np.log(2))\n",
        "#Mínimo y máximo número de capas de las redes\n",
        "min_capas = 4\n",
        "max_capas = 6\n",
        "#Mínimo y máximo número de neuronas en las capas Fully Connected\n",
        "min_neuronas = 1\n",
        "max_neuronas = 200\n",
        "#Mínimo y máximo número de filtros en las capas de las redes\n",
        "min_num_filtros = 1\n",
        "max_num_filtros = 256\n",
        "#Mínimo y máximo tamaño de los filtros\n",
        "min_tamaño_filtros = 2\n",
        "max_tamaño_filtros = 5\n",
        "\n",
        "\n",
        "#Hiperparámetros para optimizadores (Adam)\n",
        "tasa_aprendizaje = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "#Pendiente negativa de la función LeakyReLU\n",
        "pendiente_negativa_LR = 0.2\n",
        "#Número de valores aleatorios como entrada al generador (Dimensión z)\n",
        "z_dim = 100\n",
        "#Dispositivo para realizar el entrenamiento de las RN (necesario para PyTorch)\n",
        "dispositivo = 'cuda'\n",
        "#Número de imágenes de ejemplo a mostrar en el entrenamiento\n",
        "num_imagenes_mostrar = 9\n",
        "#Número de canales finales de las imágenes generadas. Un canal para imágenes en escala de grises\n",
        "num_canales_final = 1\n",
        "#Inicializador de pesos de las RN. Se utiliza una distribución normal\n",
        "inicializador_redes = torch.nn.init.normal_\n",
        "#Parámetros para inicializar pesos de las RN\n",
        "media_inicializar = 0.0\n",
        "desv_est_inicializar = 0.02\n",
        "bias_inicializar = 0.0\n",
        "#Función de costo\n",
        "criterio = nn.BCEWithLogitsLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI2DgN29Zc4L"
      },
      "source": [
        "### **Función para mostrar imágenes del generador entrenado**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VTOz0peZk94"
      },
      "source": [
        "def mostrar_imagen(predicciones,num_imagenes_mostrar = 25):\n",
        "  '''Función para mostrar mosaico de imágenes'''\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  predicciones1 = predicciones[:num_imagenes_mostrar]\n",
        "  image_tensor = (predicciones1+ 1) / 2\n",
        "  image_unflat = image_tensor.detach().cpu()\n",
        "  image_grid = make_grid(image_unflat[:num_imagenes_mostrar], nrow=5)\n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7x3a1VO9I-e"
      },
      "source": [
        "### **Obtener conjunto de imágenes MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcsvskZdmu4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "ab2d4a6bce654cd390985be3b86e4d93",
            "bfa08350d5644d748261645a956fb096",
            "049df5f3733b453e8b67e4f7ab3725a8",
            "11d387f49a90472291c8b43347b83984",
            "b7014ed11cc34bd3a860ce47791ce686",
            "df75e42d96194dfe8f8475581bc601f9",
            "eef05689cbfc4c5f9ff969632893dad6",
            "6a3e834d31cd4fb5badd0c5755296bec"
          ]
        },
        "outputId": "7daadabc-3380-4453-93ed-78a0098e334f"
      },
      "source": [
        "#Semilla de aleatoriedad que permita obtener los mismos resultados\n",
        "np.random.seed(0)\n",
        "#Obtener imágenes del conjunto de datos MNIST\n",
        "imagenes_mnist = MNIST('.', download=True,train=True).data.numpy()\n",
        "#Normalizar las imágenes en el rango [-1,1]\n",
        "imagenes_mnist = imagenes_mnist.reshape(-1,1,28,28).astype(np.float32)*2./255.0 -1. \n",
        "#Indices para escoger sólo una parte de todo el conjunto de datos\n",
        "indices = np.random.choice(imagenes_mnist.shape[0],tamaño_dataset,replace=False)\n",
        "#Escalar imágenes a una resolución 32x32\n",
        "imagenes_entrenar = torch.nn.functional.interpolate(torch.tensor(imagenes_mnist[indices]),size=resolucion_actual).numpy()\n",
        "#Crear el conjunto de datos para el entrenamiento de las GANs \n",
        "dataloader = DataLoader(imagenes_entrenar,\n",
        "    batch_size=tamaño_lote,\n",
        "    shuffle=True)\n",
        "#Indices aleatorios para elgir las imágenes que serán comparadas para el cálculo de FID\n",
        "indices = np.random.choice(imagenes_mnist.shape[0],tamaño_comparar,replace=False)\n",
        "#Crear el conjunto de imagenes para introducir a Inception v3\n",
        "imagenes_comparar = torch.nn.functional.interpolate(torch.tensor(imagenes_mnist[indices].reshape(-1,1,1,28,28)),size=(3,299,299)).numpy()\n",
        "imagenes_comparar = imagenes_comparar.reshape(-1,299,299,3)\n",
        "\n",
        "\n",
        "#Se elimina el arreglo de imágenes para vaciar la memoria\n",
        "del imagenes_entrenar, imagenes_mnist\n",
        "\n",
        "#Plasmar una muestra de imágenes\n",
        "mostrar_imagen(torch.Tensor(imagenes_comparar.reshape(-1,3,299,299)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab2d4a6bce654cd390985be3b86e4d93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqXDEJtLKH6q"
      },
      "source": [
        "### **Funciones para calcular la Fréchet Inception Distance (FID)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8-v77YK2B7i"
      },
      "source": [
        "def calcular_FID(CNN, imagenes_1, imagenes_2):\n",
        "    '''Función para calcular la Fréchet Inception Distance'''\n",
        "    # Calcular activaciones de la CNN con los dos lotes de imágenes\n",
        "    act_1 = CNN.predict(imagenes_1)\n",
        "    act_2 = CNN.predict(imagenes_2)\n",
        "    # Calcular media y covarianza de las activaciones\n",
        "    mu_1, sigma_1 = act_1.mean(axis=0), np.cov(act_1, rowvar=False)\n",
        "    mu_2, sigma_2 = act_2.mean(axis=0), np.cov(act_2, rowvar=False)\n",
        "    # Calcular la suma de las diferencias cuadradas entre las medias\n",
        "    diferencia_cuadrada = np.sum((mu_1 - mu_2)**2.0)\n",
        "    #Calcular la raíz cuadrad del producto entre covarianzas\n",
        "    raiz_cuad = scipy.linalg.sqrtm(sigma_1.dot(sigma_2))\n",
        "    # Comprobar la correctez de los números complejos en la raíz\n",
        "    if np.iscomplexobj(raiz_cuad):\n",
        "      raiz_cuad = raiz_cuad.real\n",
        "    # Calcular el puntaje\n",
        "    fid = diferencia_cuadrada + np.trace(sigma_1 + sigma_2 - 2.0 * raiz_cuad)\n",
        "    return fid\n",
        "\n",
        "def evaluar_FID(reales,falsas):\n",
        "  '''Función para procesar las imágenes para su introducción\n",
        "     a Inception v3 y posteriormente calcular el FID con los\n",
        "     vectores de características\n",
        "  '''\n",
        "  #Realizar copia de los arreglos de imágenes\n",
        "  reales1 = reales.copy()\n",
        "  falsas1 = falsas.copy()\n",
        "  #Pre-procesar las imágenes para su correcta entrada a Inception v3. Normalizar en el rango [-1,1]\n",
        "  imagenes_reales = preprocess_input(reales1)\n",
        "  imagenes_falsas = preprocess_input(falsas1)  \n",
        "  #Calcular FID\n",
        "  fid = calcular_FID(inception_modelo, imagenes_reales, imagenes_falsas)\n",
        "  #Truncar FID a cinco decimales\n",
        "  fid = round(fid, 5)\n",
        "  return fid\n",
        "\n",
        "# Cargar la red pre-enetrenada Inception v3\n",
        "inception_modelo = InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8QSE3eLfSl6"
      },
      "source": [
        "### **Función para evaluar la Aptitud de las partículas entrenadas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHYxspgjfRRT"
      },
      "source": [
        "def evaluar_aptitud(generador):\n",
        "   #Modo de evaluación del generador, necesario para evaluar correctamente su desempeño \n",
        "   generador.eval()\n",
        "   #Generar sólo 500 imágenes por cada vez que se llama el generador para no sobrecargar la memoria disponible\n",
        "   imagenes_por_lote = 50 \n",
        "   #N° de veces que se necesitará llamar al generador para obtener tantas imágenes sintéticas como las que contiene el conjunto de entrenamiento\n",
        "   num_lotes = tamaño_comparar // imagenes_por_lote\n",
        "   #Imágenes que faltaría obtener para llegar al mismo número que las imágenes de entrenamiento\n",
        "   diferencia = tamaño_comparar - (num_lotes * imagenes_por_lote)\n",
        "   for i in range(num_lotes):\n",
        "      #Se obtiene el ruido aleatorio\n",
        "      semilla = obtener_ruido(imagenes_por_lote, z_dim, dispositivo=dispositivo)\n",
        "      #Si es el primer lote de imágenes\n",
        "      if i == 0:\n",
        "        #Se crea el arreglo de imágenes. Estas se redimensiona en la forma (n° muestras, resolucion_actual, resolucion_actual, 1) ya que esa\n",
        "        #es la forma de las dimensiones que acepta la red Inception v3\n",
        "        falsas = generador(semilla).to('cpu').detach().numpy().reshape(-1, 1, resolucion_actual, resolucion_actual)\n",
        "      #Los siguientes lotes de imágenes\n",
        "      else:\n",
        "        #Se obtiene el lote de imágenes\n",
        "        temp = generador(semilla).to('cpu').detach().numpy().reshape(-1, 1, resolucion_actual, resolucion_actual)\n",
        "        #Se concatena al lote previamente creado\n",
        "        falsas = np.concatenate((falsas, temp), axis=0)\n",
        "   #Si faltan imágenes que añadir\n",
        "   if diferencia > 0:\n",
        "      #Se obtiene el ruido aleatorio\n",
        "      semilla= obtener_ruido(diferencia,z_dim,dispositivo=dispositivo)\n",
        "      #Se crea el lote de imágenes\n",
        "      temp = generador(semilla).to('cpu').detach().numpy().reshape(-1,resolucion_actual,resolucion_actual,1)\n",
        "      #Se concatena al lote previamente creado\n",
        "      falsas = np.concatenate((falsas, temp), axis=0)\n",
        "   #Redimensionar imagenes\n",
        "   falsas = torch.nn.functional.interpolate(torch.tensor(falsas.reshape(-1,1,1,resolucion_actual,resolucion_actual)),size=(3,299,299)).numpy()\n",
        "   falsas = falsas.reshape(-1,299,299,3)\n",
        "   #Se calcula el FID con ambos lotes de imágenes, las de entrenamiento y las generadas \n",
        "   aptitud = evaluar_FID(imagenes_comparar, falsas)\n",
        "   #Retornar la aptitud calculada \n",
        "   return aptitud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zyzyGfzKQY1"
      },
      "source": [
        "### **Función para inicializar los pesos de las RN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDEu0LrD2EjX"
      },
      "source": [
        "def iniciar_pesos(capa):\n",
        "    '''Función para inicializar los pesos de las RN con una distribución normal'''\n",
        "    #Si es una capa de naturaleza convolucional no tendrá bias\n",
        "    if isinstance(capa, nn.Conv2d) or isinstance(capa, nn.ConvTranspose2d):\n",
        "        inicializador_redes(capa.weight, media_inicializar, desv_est_inicializar)\n",
        "    #Si es una capa de BatchNormalization tendrá bias\n",
        "    if isinstance(capa, nn.BatchNorm2d):\n",
        "        inicializador_redes(capa.weight, media_inicializar, desv_est_inicializar)\n",
        "        torch.nn.init.constant_(capa.bias, bias_inicializar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5CmsufzNJv7"
      },
      "source": [
        "### **Función para inicializar partículas y enjambre**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocxXOa2rNQUO"
      },
      "source": [
        "#Cada generador será una lista de listas, cada lista interna tendrá la definición y parámetros de una capa, por ejemplo:\n",
        "#[[FC,4*4*1024],[T,1024,2],[C,250,4]] representa una red con una capa FC de 16,384 neuronas (el 4*4 se refiere al tamaño que queremos\n",
        "#obtener al pasar por la primera convolución transpuesta y el 1024 el n° de filtros que tendrá esa primera capa, por lo que primero se\n",
        "#tiene que saber el tamaño de la imagen que saldrá después de la primera TC y el n° de filtros en esta); después una Convolucional Transpuesta\n",
        "# con 1024 filtros de tamaño 2*2; por último una capa de Convolucional que conserva el tamaño, con 250 filtros y un tamaño de 4*4.\n",
        "\n",
        "#El tamaño final de esta red se obtiene contando el n° de transpuestas convolucionales que no mantiene el tamaño por dos y luego por el tamaño\n",
        "#de la imagen al salir de la capa FC. En la anterior red ya que hay una capa T y el tamaño inicial es de 4, se tiene que: 1*2*4=8 por lo que \n",
        "#el tamaño final de la imagen será 8*8, por lo que el n° máximo de T será igual a 4 porque de 4*4 hasta 64*64 se necesitan 4 capas que dupliquen T\n",
        "\n",
        "def inicializar_particula(inicio=True):\n",
        "  'Función para inicializar una partícula aleatoriamente'\n",
        "  #Número de capas que tendrá la red elegido aleatoriamente en el rango [min_capas,max_capas]\n",
        "  num_max_capas = np.random.randint(min_capas, max_capas+1)\n",
        "  #Lista que contendrá las capas y sus parámetros\n",
        "  particula = []\n",
        "  if inicio == True: #Si es el primer enjambre (o sea la resolución=4^2) necesita al principio una capa FC, en caso contrario no es necesaria la capa FC\n",
        "    #Número de neuronas que tendrá la capa FC elegido aleatoriamente en el rango [min_neuronas, max_neuronas]\n",
        "    numero_neuronas = np.random.randint(min_neuronas, max_neuronas+1)\n",
        "    #Se agrega la descripción en forma de lista de la capa FC (el resolucion_inicial*resolucion_inicial es porque empezará en una resolución de 4*4)\n",
        "    particula.append(['FC', resolucion_inicial*resolucion_inicial*numero_neuronas])\n",
        "    num_max_capas -= 1 #Se resta una capa, ya que sólo faltan n-1 capas, ya que una ya se ocupó\n",
        "  #Contador de la capas Transpuestas convolucionales que duplican la resolución. Se requiere un registro para no escalar de más la imagen.\n",
        "  num_capas_T = 0\n",
        "  #Por las n_capas capas que faltan de la red\n",
        "  for i in range(num_max_capas):\n",
        "    #Se calcula el número de transpuestas faltantes (ya que se necesitan 4 para llegar de 4*4 a 64*64)\n",
        "    #Ejemplo: Si ya van 3 capas T y va en la i=6 con un máximo de capas de 10, entonces:\n",
        "    #4-3 < (10-1)-6, significa que aún quedan 3 capas que insertar y sólo falta una capa Transpuesta por lo que se puede dejar al azar. \n",
        "    if num_max_capas_T-num_capas_T  < (num_max_capas)-i:\n",
        "      #Se elige un número aleatorio 0 ó 1 y dependiendo de ese valor es la capa que se agrega\n",
        "      aleat = np.random.randint(2)\n",
        "      #Si el aleatorio es 0 y aún falta agregar más capas T\n",
        "      if aleat == 0 and num_capas_T < num_max_capas_T:\n",
        "        #Se elige aleatoriamente el n° de filtros que tendra la capa y el tamaño de esta\n",
        "        numero_filtros = np.random.randint(min_num_filtros, max_num_filtros+1)\n",
        "        tamaño_filtros = np.random.randint(min_tamaño_filtros, max_tamaño_filtros+1)\n",
        "        #Se añade a la lista del generador esta capa con sus parámetros\n",
        "        particula.append(['T', numero_filtros, tamaño_filtros])\n",
        "        #Se suma uno al contador de estas capas\n",
        "        num_capas_T += 1\n",
        "      #Si es cero se agrega una capa Convolucional que mantiene el tamaño, o sea, una TM\n",
        "      else:\n",
        "        #Se eligen aleatoriamente los parámetros de esta capa\n",
        "        numero_filtros = np.random.randint(min_num_filtros, max_num_filtros+1)\n",
        "        tamaño_filtros = np.random.randint(min_tamaño_filtros, max_tamaño_filtros+1)\n",
        "        #Se añade la descripción de la capa a la red\n",
        "        particula.append(['C',numero_filtros,tamaño_filtros])\n",
        "    ##Si sólo quedara el número justo de capas para insertar las restantes Transpuestas que duplican el tamaño, \n",
        "    #entonces se inserta obligatoriamente una Transpuesta que duplica la resolución\n",
        "    else:\n",
        "      #Se elige aleatoriamente el n° de filtros que tendra la capa y el tamaño de esta\n",
        "      numero_filtros = np.random.randint(min_num_filtros, max_num_filtros+1)\n",
        "      tamaño_filtros = np.random.randint(min_tamaño_filtros, max_tamaño_filtros+1)\n",
        "      #Se añade a la lista del generador esta capa con sus parámetros\n",
        "      particula.append(['T', numero_filtros, tamaño_filtros])\n",
        "      #Se suma uno al contador de estas capas\n",
        "      num_capas_T += 1\n",
        "\n",
        "  #Se regresa la lista representando a la partícula\n",
        "  return particula\n",
        "  \n",
        "\n",
        "def inicializar_enjambre(num_particulas,inicio=True):\n",
        "  '''Función para inicializar el enjambre añadiendo tantas partículas como se necesite'''\n",
        "  #El parámetro inicio sirve para indicar que se necesitan partículas con capa FC al principio\n",
        "  #esto sólo se requiere cuando se inicia la corrida en una resolución de 4^2\n",
        "  enjambre = []\n",
        "  for i in range(num_particulas):\n",
        "    enjambre.append(inicializar_particula(inicio=inicio))\n",
        "  return enjambre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJAnstm6ZQOO"
      },
      "source": [
        "### **Función para redimensionar salida de las capas Fully Connected a una imagen de 4*4** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apxo2POuVzwd"
      },
      "source": [
        "class Redimensionar_FC(nn.Module):\n",
        "    '''\n",
        "    Clase de PyTorch para redimensionar la salida de la primera capa Fully Connected a la forma de una imágen de 4*4*canales para su entrada\n",
        "    en las siguientes capas convolucionales \n",
        "    '''\n",
        "    #Recibe de entrada las dimensiones de a las cuales redimensionar\n",
        "    def __init__(self, dimensiones):\n",
        "        super().__init__()\n",
        "        self.dimensiones = dimensiones\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Redimensionar_FC{self.dimensiones}'\n",
        "\n",
        "    def forward(self,entrada):\n",
        "        '''\n",
        "        Redimensionar la entrada de acuerdo a las dimensiones establecidas en su creación\n",
        "        '''\n",
        "        #La primera dimsensión de la entrada indica el tamaño del lote (n° de imágenes o entradas)\n",
        "        tamaño_lote = entrada.size(0)\n",
        "        #Crear las nuevas dimensiones con el tamaño de lote\n",
        "        dimensiones = (tamaño_lote,*self.dimensiones)\n",
        "        #Obtener la salida con las nuevas dimensiones\n",
        "        return entrada.view(dimensiones)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81kXNkdcBheh"
      },
      "source": [
        "### **Función para definir los hiperparámetros de las capas de naturaleza convolucional**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N60ZX8cOBttO"
      },
      "source": [
        "#Función para definir hiperparámetros de las capas \n",
        "#Se cambian sólo los valores de stride (1 para conservar tamaño y 2 para duplicarlo).\n",
        "#Se cambian los valores de 'output_padding' para ajustar el tamaño saliente de la imagen.\n",
        "\n",
        "#Caso 1: Se tiene una capa Transpuesta convolucional que se encarga de duplicar las dimensiones de la entrada (capa 'T').\n",
        "#Para definirla se necesitan los hiperparámetros: stride, dilatación, output_padding y padding. Todos estos parámetros excepto 'padding' se mantienen fijos\n",
        "#según el caso de que las dimensiones del filtro sean pares o impares. 'Padding' necesita ser calculado con la siguiente fórmula:\n",
        "#Despejando 'Padding' en la fórmula para calcular las dimensiones de salida de una capa Transpuesta Conv. (https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)\n",
        "#Padding = ((H_in-1) * stride + dil * (kernel_size - 1) + output_padding + 1 - H_out) / 2\n",
        "\n",
        "#Caso 2: Se tiene ina capa Convolucional que conserva las dimensiones de la entrada (capa 'C').\n",
        "#Para definirla se necesitan los hiperparámetros: stride, dilatación y padding. Todos estos parámetros excepto 'padding' se mantienen fijos\n",
        "#según el caso de que las dimensiones del filtro sean pares o impares. 'Padding' necesita ser calculado con la siguiente fórmula:\n",
        "#Despejando 'Padding' en la fórmula para calcular las dimensiones de salida de una capa Convolucional (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "#Padding = ((H_out-1) * stride - H_in + dilation * (kernel_size - 1) + 1) / 2 \n",
        "def definir_hiperparametros(tipo_capa, tamaño_filtro, dimension_entrada):\n",
        "  '''Función para calcular el padding de las capas trasnpuesta convolucional para que se obtengan\n",
        "     salidas que dupliquen o conserven el tamaño de entrada según sea el caso\n",
        "  '''\n",
        "  #Si el fitlro tiene un tamaño par\n",
        "  if tamaño_filtro % 2 == 0:\n",
        "    #Si es una capa para conservar el tamaño de entrada, se inserta una capa Convolucional\n",
        "    if tipo_capa == 'C':\n",
        "      #Se conserva la dimsensión de entrada\n",
        "      dimension_salida = dimension_entrada\n",
        "      #Se fijan los hiperparámetros necesarios para obtener la salida deseada\n",
        "      output_padding = 0 \n",
        "      stride = 1\n",
        "      dilatacion = 2\n",
        "      #Se calcula el padding mediante la fórmula despejada anteriormente mencionada\n",
        "      padding = ((dimension_salida - 1) * stride - dimension_entrada + (dilatacion * (tamaño_filtro - 1)) + 1) / 2\n",
        "    #Si es una capa para duplicar el tamaño de entrada\n",
        "    elif tipo_capa == 'T':\n",
        "      #Se duplica la dimensión de salida\n",
        "      dimension_salida = dimension_entrada * 2\n",
        "      #Se fijan los hiperparámetros necesarios para obtener la salida deseada\n",
        "      output_padding = 0\n",
        "      stride = 2\n",
        "      dilatacion = 1\n",
        "      #Se calcula el padding mediante la fórmula despejada anteriormente mencionada\n",
        "      padding = ((dimension_entrada - 1) * stride + dilatacion * (tamaño_filtro - 1) + output_padding + 1 - dimension_salida) / 2\n",
        "  #Si el filtro tiene tamaño impar\n",
        "  else:\n",
        "    #Si es una capa para conservar el tamaño de entrada, se inserta una capa Convolucional\n",
        "    if tipo_capa == 'C':\n",
        "      #Se conserva la dimsensión de entrada\n",
        "      dimension_salida = dimension_entrada\n",
        "      #Se fijan los hiperparámetros necesarios para obtener la salida deseada\n",
        "      output_padding = 0\n",
        "      stride = 1\n",
        "      dilatacion = 1\n",
        "      #Se calcula el padding mediante la fórmula despejada anteriormente mencionada\n",
        "      padding = ((dimension_salida - 1) * stride - dimension_entrada + (dilatacion * (tamaño_filtro - 1)) + 1) / 2\n",
        "    #Si es una capa para duplicar el tamaño de entrada\n",
        "    elif tipo_capa == 'T':\n",
        "      #Se duplica la dimensión de salida\n",
        "      dimension_salida = dimension_entrada * 2\n",
        "      #Se fijan los hiperparámetros necesarios para obtener la salida deseada\n",
        "      output_padding = 1\n",
        "      stride = 2\n",
        "      dilatacion = 1\n",
        "      #Se calcula el padding mediante la fórmula despejada anteriormente mencionada\n",
        "      padding = ((dimension_entrada - 1) * stride + dilatacion * (tamaño_filtro - 1) + output_padding + 1 - dimension_salida) / 2\n",
        "\n",
        "  #Regresar los hiperparámetros necesarios para definir la capas de naturaleza convolucional\n",
        "  return int(padding), int(output_padding), int(stride), int(dilatacion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2QEpr6bdjEX"
      },
      "source": [
        "### **Función para crear las capas para el Generador**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_Rzc56Qdw2F"
      },
      "source": [
        "def obtener_capas_generador(canales_entrada, canales_salida, tamaño_filtro = 3, stride = 2, padding = 2, dilatacion = 1, output_padding = 1, capa_final = False):\n",
        "    '''Función para crear las capas de naturaleza convolucional para el Generador con Normalización de pesos (Weight Normalization), esto mediante\n",
        "      la función de PyTorch (nn.utils.weight_norm)\n",
        "    '''\n",
        "    #Si el stride es igual a dos entonces es una capa que desea duplicar el tamaño de la entrada, o sea, una capa transpuesta convolucional\n",
        "    if stride == 2:\n",
        "      #Si no es la capa final, entonces se inserta un bloque de capas compuesto por una capa transpuesta convolucional + capa Batch normalization + capa ReLU \n",
        "      if not capa_final:\n",
        "          return nn.Sequential(\n",
        "                nn.utils.weight_norm(nn.ConvTranspose2d(canales_entrada, canales_salida, tamaño_filtro, stride, padding=padding, dilation=dilatacion, output_padding=output_padding, bias=False)),\n",
        "                nn.BatchNorm2d(canales_salida),\n",
        "                nn.ReLU(inplace=True),\n",
        "          )\n",
        "      #Si es la capa final, sólo se usa la capa transpuesta convolucional + Tanh\n",
        "      else:\n",
        "          return nn.Sequential(\n",
        "              nn.utils.weight_norm(nn.ConvTranspose2d(canales_entrada, canales_salida, tamaño_filtro, stride, padding=padding, dilation=dilatacion, output_padding=output_padding, bias=False)),\n",
        "              nn.Tanh(),\n",
        "          )\n",
        "    #Si el stride es de 1, entonces se inserta una capa convolucional que mantiene el tamaño de entrada\n",
        "    else:\n",
        "      #Si no es la capa final, entonces se inserta un bloque de capas compuesto por una capa convolucional + capa Batch normalization + capa ReLU \n",
        "      if not capa_final:\n",
        "          return nn.Sequential(\n",
        "              nn.utils.weight_norm(nn.Conv2d(canales_entrada, canales_salida, tamaño_filtro, stride, padding=padding, dilation=dilatacion, bias=False)),\n",
        "              nn.BatchNorm2d(canales_salida),\n",
        "              nn.ReLU(inplace=True),\n",
        "          )\n",
        "      #Si es la capa final, sólo se usa la capa convolucional + Tanh\n",
        "      else:\n",
        "          return nn.Sequential(\n",
        "              nn.utils.weight_norm(nn.Conv2d(canales_entrada, canales_salida, tamaño_filtro, stride, padding=padding, dilation=dilatacion, bias=False)),\n",
        "              nn.Tanh(),\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwJChu1slT3v"
      },
      "source": [
        "### **Función para crear las capas para el Discriminador**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLM5w9dalT36"
      },
      "source": [
        "def obtener_capas_discriminador(canales_entrada, canales_salida, tamaño_filtro = 4, stride = 2, capa_final = False):\n",
        "    '''Función para crear las capas de naturaleza convolucional para el Discriminador con Normalización Espectral (Spectral Normalization), esto mediante\n",
        "      la función de PyTorch (nn.utils.spectral_norm)\n",
        "    '''\n",
        "      \n",
        "    #Si no es la capa final, entonces se inserta un bloque de capas compuesto por una capa convolucional + capa Batch normalization + capa LeakyReLU \n",
        "    if not capa_final:\n",
        "            return nn.Sequential(\n",
        "                nn.utils.spectral_norm(nn.Conv2d(canales_entrada, canales_salida, tamaño_filtro, stride)),\n",
        "                nn.BatchNorm2d(canales_salida),\n",
        "                nn.LeakyReLU(pendiente_negativa_LR, inplace=True),\n",
        "            )\n",
        "    #Si es la capa final, sólo se usa la capa convolucional\n",
        "    else:\n",
        "        return nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(canales_entrada, canales_salida, tamaño_filtro, stride)),\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzCfovmM-OUY"
      },
      "source": [
        "### **Función para decodificar el generador a partir de la partícula (Lista)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVUt5I2_-aST"
      },
      "source": [
        "def decodificar_generador(particula,z_dim):\n",
        "  '''\n",
        "    Función que decodifica un Generador a partir de la lista que define a la partícula\n",
        "  '''\n",
        "  #El número de capas es la longitud de la lista que encripta la particula.\n",
        "  num_capas = len(particula)\n",
        "  #Iniciar lista de capas\n",
        "  capas = []\n",
        "  #Variable que contiene la resolución de la imagen que se generará con las capas insertadas hasta el momento. Comienza con la resolución inicial de 4*4\n",
        "  resolucion_actual = resolucion_inicial\n",
        "  #Variable que contiene el n° de canales de entrada de cada nueva capa, este se actualiza según los canales de salida de la capa previa.\n",
        "  #Al inicio recibe tantos canales como números aleatorios de entrada al generador (z_dim)\n",
        "  canales_entrada = z_dim\n",
        "  #Añade una capa FC con el número de neuronas que indica la primera capa de la partícula en su 2da posición. \n",
        "  #Notar que se utiliza la normalización de pesos proporcionada por la librería de PyTorch (nn.utils.weight_norm)\n",
        "  capas.append(nn.utils.weight_norm(nn.Linear(canales_entrada, particula[0][1])))\n",
        "  #Se actualiza el tamaño de entrada, este será el mismo que el n° de canales de salida de la capa anterior.\n",
        "  #Recordar que cuando se inicializaron las partículas (función 'Inicializar partícula') se múltiplico el n° de neuronas por la resolución inicial, por lo que\n",
        "  #se tendrá un canal por cada neurona de la capa Fully Connected y de resolución tamaño_inicial*tamaño_inicial\n",
        "  canales_entrada = int(particula[0][1] / (resolucion_inicial*resolucion_inicial))\n",
        "  #Se inserta una capa de la clase 'Redimensionar_FC' que realizará la redimensión de las salidas de la capa Fully Connected\n",
        "  capas.append(Redimensionar_FC((canales_entrada, resolucion_inicial, resolucion_inicial)))\n",
        "  #Por cada capa faltante en la partícula\n",
        "  for i in range(1, num_capas):\n",
        "    #Si la particula es una transpuesta que duplica las dimensiones de entrada\n",
        "    if particula[i][0] == 'T':\n",
        "      tamaño_filtro = particula[i][2]\n",
        "      if tamaño_filtro > resolucion_actual:\n",
        "        tamaño_filtro = resolucion_actual\n",
        "      #Calcular hiperparámetros necesarios (padding, output_padding, stride, dilatación) para que la capa cumpla con su meta de duplicar las \n",
        "      #dimensiones de entrada, estos se calculan con la función 'definir_hiperparametros'\n",
        "      padding, output_padding, stride, dilatacion = definir_hiperparametros('T', tamaño_filtro, resolucion_actual)\n",
        "      #Añadir una capa transpuesta que duplica las dimensiones de la entrada con los hiperparámetros calculados utilizando la función 'obtener_capas_generador'\n",
        "      capa = obtener_capas_generador(canales_entrada, particula[i][1], tamaño_filtro = tamaño_filtro, stride=stride, padding = padding, dilatacion=dilatacion, \\\n",
        "                         output_padding = output_padding, capa_final=False)\n",
        "      #Añadir la capa obtenida a la lista de capas\n",
        "      capas.append(capa)\n",
        "      #Se duplica la resolución, ya que se insertó una capa que duplica las dimensiones de la entrada\n",
        "      resolucion_actual *= 2\n",
        "      #Se actualizan los canales de entrada con el número de canales de salida indicados por la lista de la partícula\n",
        "      canales_entrada = particula[i][1]\n",
        "    #Si la cpa es una convolucional que conserva las dimensiones de la entrada  \n",
        "    elif particula[i][0] == 'C':\n",
        "      tamaño_filtro = particula[i][2]\n",
        "      if tamaño_filtro > resolucion_actual:\n",
        "        tamaño_filtro = resolucion_actual\n",
        "      #Calcular hiperparámetros necesarios (padding, output_padding, stride, dilatación) para que la capa cumpla con su meta de duplicar las \n",
        "      #dimensiones de entrada, estos se calculan con la función 'definir_hiperparametros'\n",
        "      padding, output_padding, stride, dilatacion = definir_hiperparametros('C', tamaño_filtro, resolucion_actual)\n",
        "      #Añadir una capa transpuesta que duplica las dimensiones de la entrada con los hiperparámetros calculados utilizando la función 'obtener_capas_generador'\n",
        "      capa = obtener_capas_generador(canales_entrada, particula[i][1], tamaño_filtro = tamaño_filtro, stride=stride, padding = padding, dilatacion=dilatacion, \\\n",
        "                         output_padding = output_padding, capa_final=False)\n",
        "      #Añadir la capa obtenida a la lista de capas\n",
        "      capas.append(capa)\n",
        "      #Se actualizan los canales de entrada con el número de canales de salida indicados por la lista de la partícula\n",
        "      canales_entrada = particula[i][1]\n",
        "      #NOTA: No se actualizó la resolución actual ya que al ser una capa que mantiene el tamaño de la entrada entonces la resolución permanece igual\n",
        "\n",
        "  #Por último se añade una capa Convolucional que conserva el tamaño de la entrada con un filtro de tamaño uno para 'pulir' la salida del generador\n",
        "  #Calcular hiperparámetros necesarios (padding, output_padding, stride, dilatación) para que la capa cumpla con su meta de duplicar las \n",
        "  #dimensiones de entrada, estos se calculan con la función 'definir_hiperparametros'\n",
        "  padding, output_padding, stride, dilatacion = definir_hiperparametros('C', 1, resolucion_actual)\n",
        "  capa = obtener_capas_generador(canales_entrada, 1, tamaño_filtro = 1, stride=stride, padding = padding, dilatacion=dilatacion, \\\n",
        "                      output_padding = output_padding, capa_final=True)\n",
        "  #Añadir la capa obtenida a la lista de capas\n",
        "  capas.append(capa)\n",
        "  #Crear el generador con la secuencia de capas en la lista\n",
        "  generador = nn.Sequential(*capas)\n",
        "  #Regresar el Generador\n",
        "  return generador"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYdNSqUknEl9"
      },
      "source": [
        "### **Función para decodificar el discriminador a partir de la partícula (Lista)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LvlcYr5nI_5"
      },
      "source": [
        "def decodificar_discriminador(particula, num_canales = num_canales_final, resolucion = resolucion_actual):\n",
        "  '''\n",
        "    Función que decodifica un Discriminador a partir de la lista que define a la partícula\n",
        "  '''\n",
        "  #Se realiza una copia de la lista y se invierte su secuencia\n",
        "  particula_inversa = particula.copy()\n",
        "  particula_inversa.reverse()\n",
        "  #El número de capas es la longitud de la lista que encripta la particula\n",
        "  num_capas = len(particula_inversa)\n",
        "  #Número de canales \n",
        "  num_canales_actual = num_canales\n",
        "  #Resolución actual\n",
        "  resolucion_actual = resolucion\n",
        "  #Iniciar lista de capas \n",
        "  capas = []\n",
        "  #Iniciar lista donde se encuentren los índices de las capas de tipo T que son las que se convertirán a Convolucionales que reducen\n",
        "  #las dimensiones de la entrada\n",
        "  indices_transpuestas = []\n",
        "  #Añadir los índices de la partícula donde se encuentran las capas del tipo T \n",
        "  for i in range(num_capas):\n",
        "     if particula_inversa[i][0] == 'T':\n",
        "        indices_transpuestas.append(i)\n",
        "\n",
        "  #Por cada capa del tipo T en la partícula\n",
        "  for indice in indices_transpuestas:\n",
        "    #Comprobar que la resolución actual no sea mayor que el tamaño del filtro a poner, ya que eso no es posible de implementar\n",
        "    if particula_inversa[indice][2] > resolucion_actual:\n",
        "      tamaño_filtro =  resolucion_actual\n",
        "    else:\n",
        "      tamaño_filtro = particula_inversa[indice][2]\n",
        "    #Se añade una capa Convolucional con normalización espectral \n",
        "    capa = obtener_capas_discriminador(num_canales_actual, particula_inversa[indice][1], tamaño_filtro = tamaño_filtro)\n",
        "    #Añadir la capa a la lista de capas\n",
        "    capas.append(capa)\n",
        "    #Se actualiza el número de canales\n",
        "    num_canales_actual = particula_inversa[indice][1]\n",
        "    #Se calcula la nueva resolución con la fórmula de las capas Convolucionales (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "    resolucion_actual = np.floor(((resolucion_actual - (tamaño_filtro - 1) - 1) / 2) + 1 )\n",
        "    \n",
        "\n",
        "  #Añadir capa final Fully Connected que se encuentra al final de la partícula inversa.\n",
        "  #Primero calcular el número de entradas a la capa FC\n",
        "  num_pixeles = int(resolucion_actual * resolucion_actual * num_canales_actual)\n",
        "  #Añadir capa que 'aplane' esos valores de las capas convolucionales\n",
        "  capas.append(Redimensionar_FC(([num_pixeles])))\n",
        "  #Insertar la capa FC con los canales solicitados\n",
        "  \n",
        "  capas.append(nn.utils.spectral_norm(nn.Linear(int(num_pixeles),int(particula_inversa[-1][1] / (resolucion_inicial * resolucion_inicial)))))\n",
        "  #Insertar capa FC que convierta obtenga el valor final que servirá como predicción.  El '1' en la capa representa que sólo se requiere una salida (predicción)\n",
        "  capas.append(nn.utils.spectral_norm(nn.Linear(int(particula_inversa[-1][1] / (resolucion_inicial * resolucion_inicial)), 1)))\n",
        "  #Se crea el discrimnador con la secuencia de las capas\n",
        "  discriminador = nn.Sequential(*capas)\n",
        "  #Se retorna el discriminador\n",
        "  return discriminador\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTr-5u_onftt"
      },
      "source": [
        "### **Función para obtener ruido aleatorio**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3kRrjEvnCgn"
      },
      "source": [
        "def obtener_ruido(num_muestras, z_dim, dispositivo='cpu'):\n",
        "    '''Función para obtener el ruido aleatorio normal que será la entrada al generador'''\n",
        "    return torch.randn(num_muestras, z_dim, device=dispositivo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-YuSNyOPTnA"
      },
      "source": [
        "### **Función para realizar el entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8fvTAH7PXsS"
      },
      "source": [
        "def paso_entrenamiento(imagenes, generador, gen_opt, discriminador, disc_opt):\n",
        "  '''Función para realizar el entrenamiento de la GAN'''\n",
        "  tamaño_lote_actual = len(imagenes)\n",
        "  imagenes = imagenes.to(dispositivo)\n",
        "  ## Actualizar discriminador ##\n",
        "  disc_opt.zero_grad()\n",
        "  ruido_falso = obtener_ruido(tamaño_lote_actual, z_dim, dispositivo=dispositivo)\n",
        "  falso = generador(ruido_falso)\n",
        "  pred_disc_falso = discriminador(falso.detach())\n",
        "  perd_pred_disc_falso = criterio(pred_disc_falso, torch.zeros_like(pred_disc_falso))\n",
        "  pred_disc_real = discriminador(imagenes)\n",
        "  perd_pred_disc_real= criterio(pred_disc_real, torch.ones_like(pred_disc_real))\n",
        "  perdida_discriminador = (perd_pred_disc_falso + perd_pred_disc_real) / 2\n",
        "  # Actualizar gradientes\n",
        "  perdida_discriminador.backward(retain_graph=True)\n",
        "  # Actualizar optimizador\n",
        "  disc_opt.step()\n",
        "\n",
        "  ## Actualizar generador ##\n",
        "  gen_opt.zero_grad()\n",
        "  ruido_falso_2 = obtener_ruido(tamaño_lote_actual, z_dim, dispositivo=dispositivo)\n",
        "  falso_2 = generador(ruido_falso_2)\n",
        "  pred_disc_falso = discriminador(falso_2)\n",
        "  perdida_generador = criterio(pred_disc_falso, torch.ones_like(pred_disc_falso))\n",
        "  #Actualizar gradientes\n",
        "  perdida_generador.backward()\n",
        "  #Actualizar generador\n",
        "  gen_opt.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GRQSn98QH6a"
      },
      "source": [
        "### **Función para realizar el entrenamiento completo de una partícula**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fJYzVq6QO1Z"
      },
      "source": [
        "def entrenar(particula, num_epocas, dataset):\n",
        "    #Se decodifica el generador\n",
        "    gen = decodificar_generador(particula,z_dim).to(dispositivo)\n",
        "    #Se inicializan los pesos del generador\n",
        "    gen = gen.apply(iniciar_pesos)\n",
        "    #Se inicializa el optimizador del generador (Adam)\n",
        "    gen_opt = torch.optim.Adam(gen.parameters(), lr = tasa_aprendizaje, betas = (beta1, beta2))\n",
        "    #Se decodifica el discriminador\n",
        "    disc = decodificar_discriminador(particula).to(dispositivo)\n",
        "    #Se inicializa el optimizador del discriminador (Adam) \n",
        "    disc_opt = torch.optim.Adam(disc.parameters(), lr = tasa_aprendizaje, betas = (beta1, beta2))\n",
        "    #Se inicializan los pesos del discriminador\n",
        "    disc = disc.apply(iniciar_pesos)\n",
        "    #Por el número de épocas definido\n",
        "    for epoca in tqdm(range(num_epocas)):\n",
        "      #Por cada mini-lote de imágenes del conjunto de imágenes completo\n",
        "        for real in dataset:\n",
        "          paso_entrenamiento(real, gen, gen_opt, disc, disc_opt)\n",
        "    #Retornar el generador y el discriminador      \n",
        "    return gen, disc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO0x9MKCUM0e"
      },
      "source": [
        "### **Función para crear una capa creada aleatoriamente**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHox7TrlUUDy"
      },
      "source": [
        "def regresar_capa(tipo_capa):\n",
        "    '''\n",
        "      Función que regresa una capa con hiperparámetros aleatorios\n",
        "    '''\n",
        "    if tipo_capa == 'FC':\n",
        "      numero_neuronas = np.random.randint(min_num_filtros,max_num_filtros+1)\n",
        "      #Si es una capa FC esta sólo se maneja con la resolución inicial\n",
        "      return ['FC',resolucion_inicial*resolucion_inicial*numero_neuronas]\n",
        "    elif tipo_capa == 'T':\n",
        "      #Se elige aleatoriamente el n° de filtros que tendra la capa y el tamaño de esta\n",
        "      numero_filtros = np.random.randint(min_num_filtros,max_num_filtros+1)\n",
        "      tamaño_kernel = np.random.randint(min_tamaño_filtros,max_tamaño_filtros+1)\n",
        "      #Se añade a la lista del generador esta capa con sus parametros\n",
        "      return ['T',numero_filtros,tamaño_kernel]\n",
        "    else:\n",
        "      #Se elige aleatoriamente el n° de filtros que tendra la capa y el tamaño de esta\n",
        "      numero_filtros = np.random.randint(min_num_filtros,max_num_filtros+1)\n",
        "      tamaño_kernel = np.random.randint(min_tamaño_filtros,max_tamaño_filtros+1)\n",
        "      #Se añade a la lista del generador esta capa con sus parametros\n",
        "      return ['C',numero_filtros,tamaño_kernel]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPL4G-2SSwc6"
      },
      "source": [
        "### **Función para actualizar las partículas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxM3adnuS3q7"
      },
      "source": [
        "def actualizar_particula(gbest, pbest, particula):\n",
        "  '''\n",
        "    Función para actualizar las partículas utilizando el gBest y pBest\n",
        "  '''\n",
        "  #Se toma la longitud del mayor de las partículas, ya que esas dos serán las prioritarias en la comparación, por lo que aunque la partícula sea más grande\n",
        "  #que estas dos, después de la actualización no podrá ser más grande que las partícula más larga contra la que compararse, cualquier exceso será eliminado.\n",
        "  if len(gbest) > len(pbest):\n",
        "    longitud = len(gbest)\n",
        "  else:\n",
        "    longitud = len(pbest)\n",
        "  #Inicializar lista de capas de la nueva partícula\n",
        "  nueva_particula=[]\n",
        " \n",
        "  #Para todas la capas a partir de un índice de partida (ya que cuando la arquitectura ya este fija en un determinado tamaño entonces\n",
        "  #no se pueden cambiar las capas anteriores)\n",
        "  for i in range(longitud):\n",
        "    #Aleatorio para decidir si se comparará con gbest o pbest\n",
        "    r = np.random.uniform()\n",
        "    try:\n",
        "      tipo_capa = particula[i][0]\n",
        "       #Si la partícula es una Fully Connected\n",
        "      if tipo_capa == 'FC':\n",
        "        #Comparar con el gbest\n",
        "        if r <= Cg:\n",
        "          #Si el número de neuronas son iguales del gbest y la particula\n",
        "          if particula[0][1] == gbest[0][1]:\n",
        "            #Se conserva la misma capa FC de la particula\n",
        "            nueva_particula.append(particula[0]) \n",
        "          #Si no se agrega la del mejor global\n",
        "          else:\n",
        "            nueva_particula.append(regresar_capa(gbest[0][0]))\n",
        "        \n",
        "        else:\n",
        "          #Si la particula y el pbest tienen el mismo número de neuronas\n",
        "          if particula[0][1] == pbest[0][1]:\n",
        "            #Se conserva la capa FC de la particula\n",
        "            nueva_particula.append(particula[0]) \n",
        "          else:\n",
        "            #Si no se toma la del pbest\n",
        "            nueva_particula.append(regresar_capa(pbest[0][0]))\n",
        "    #Caso cuando alguna de las partículas termina\n",
        "    except IndexError:\n",
        "      pass\n",
        "    #Si la partícula es una capa convolucional ('C') o convolucional transpuesta ('T')\n",
        "    if tipo_capa == 'C' or tipo_capa == 'T':\n",
        "      #Comparar con el gbest\n",
        "      if r <= Cg:\n",
        "        try:\n",
        "          #Pueden darse tres casos:\n",
        "          #1.- Tanto la particula como el gbest son igual de largos hasta esa posición, por lo cual se pueden comparar capas\n",
        "          #2.- El gbest es más corto\n",
        "          #3.- La partícula es más corta\n",
        "          #Se lee el tipo de capa\n",
        "          valor_particula = particula[i][0]\n",
        "          valor_mejor = gbest[i][0]\n",
        "          valor_local = pbest[i][0]\n",
        "          #Si el tipo de capa de la partícula es igual a la del gbest\n",
        "          if valor_particula == valor_mejor:\n",
        "            #Y además el tipo de capa de la partícula es igual a la del pbest\n",
        "            if valor_particula == valor_local:\n",
        "              #Se agrega la capa del gbest, siguiendo el ejemplo de la Fig. 4 de Junior del caso especial donde los tipos de capas que tiene el pbest, gbest y la aprtícula son los mismos\n",
        "              nueva_particula.append(gbest[i])\n",
        "            #En caso de que no sea igual también al pbest se conserva el valor de la partícula, porque según la figura 3 si el gbest y la particula tienen la misma capa entonces se conserva intacta\n",
        "            else:\n",
        "              nueva_particula.append(particula[i])\n",
        "          #Si son diferentes los tipos de capas, se le da preferencia al gbest y se conserva esa capa\n",
        "          else:\n",
        "            nueva_particula.append(gbest[i])\n",
        "          #En el caso dos significa que como el gbest es la particula prioritaria en la diferencia eso significa que esa posición se debe eliminar de la partícula\n",
        "          #por lo que al pasar al siguiente bloque, volverá a dar error llamar ese índice de el gbest por lo que continuará el algoritmo ignorando esa posición\n",
        "          #En el caso tres, se agreagará a la nueva partícula un tipo de capa como la del gbest ya que tiene prioridad en la diferencia\n",
        "        except IndexError:\n",
        "          try:\n",
        "            nueva_particula.append(regresar_capa(gbest[i][0]))\n",
        "          except IndexError:\n",
        "            continue\n",
        "      \n",
        "      #Los casos anteriores se repiten para cuando se elige el pbest\n",
        "      else:\n",
        "        try:\n",
        "          valor_particula = particula[i][0]\n",
        "          valor_local = pbest[i][0]\n",
        "          valor_mejor = gbest[i][0]\n",
        "          if valor_particula == valor_local:\n",
        "            if valor_particula == valor_mejor:\n",
        "              nueva_particula.append(pbest[i])\n",
        "            else:\n",
        "              nueva_particula.append(particula[i])\n",
        "          else:\n",
        "            nueva_particula.append(pbest[i])\n",
        "\n",
        "        except IndexError:\n",
        "          try:\n",
        "            nueva_particula.append(regresar_capa(pbest[i][0]))\n",
        "          except IndexError:\n",
        "            continue\n",
        "  #Listas que llevan el registro de dónde se encuentran las capas de tipo 'T' y 'C'\n",
        "  indices_T = []\n",
        "  indices_C = []\n",
        "  for i in range(len(nueva_particula)):\n",
        "    if nueva_particula[i][0] == 'T': \n",
        "      indices_T.append(i)\n",
        "    else:\n",
        "      indices_C.append(i)\n",
        "  #Si faltan capas que doblan tamaño\n",
        "  if len(indices_T) < num_max_capas_T:\n",
        "    try:\n",
        "      indices_cambiar = np.random.choice(len(indices_C),num_max_capas_T-len(indices_T),replace=False)\n",
        "      for indice in indices_cambiar:\n",
        "       \n",
        "        #Se añade a la lista del generador esta capa con sus parametros\n",
        "        nueva_particula[indices_C[indice]] = regresar_capa('T')\n",
        "    except ValueError:\n",
        "      nueva_particula.append(regresar_capa('T'))\n",
        "    \n",
        "\n",
        "   \n",
        "    \n",
        "  #Si hay más T que las permitidas\n",
        "  elif len(indices_T) > num_max_capas_T:\n",
        "    indices_cambiar = np.random.choice(len(indices_T),len(indices_T)-num_max_capas_T,replace=False)\n",
        "    for indice in indices_cambiar:\n",
        "    \n",
        "      \n",
        "      #Se añade a la lista del generador esta capa con sus parametros\n",
        "      nueva_particula[indices_T[indice]] = regresar_capa('C')\n",
        "    \n",
        "  #Se retorna la nueva partícula\n",
        "  return nueva_particula"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03RN24HuU_rC"
      },
      "source": [
        "### **Función para realizar el entrenamiento de un enjambre de partículas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geARHhINVFIx"
      },
      "source": [
        "def evolucionar(num_particulas, num_generaciones, num_epocas, dataset, resolucion_actual, num_imagenes_mostrar=25, inicio = False):\n",
        "    '''\n",
        "      Función para evolucionar el enjambre de partículas\n",
        "    '''\n",
        "    #Generación inicial\n",
        "    generacion_actual = 1\n",
        "    #Inicio el enjambre\n",
        "    enjambre = inicializar_enjambre(num_particulas, inicio=inicio)\n",
        "    #Genero un array con el valor de fitness de cada individuo (que empieza alto) FID más bajo mejor\n",
        "    p_best_apt = [1000] * num_particulas\n",
        "    #Inicializo la aptitud del mejor global\n",
        "    g_best_apt = 1000\n",
        "    #Inicializo la lista de los pBest\n",
        "    p_bests = enjambre.copy()\n",
        "    #Inicializo el mejor global\n",
        "    g_best = None\n",
        "    #Listas para realizar el seguimiento de la evolución de las partículas\n",
        "    lista_aptitud_mejor = []\n",
        "   \n",
        "\n",
        "    \n",
        "    #Semilla para las imágenes que se guardarán de prueba\n",
        "    semilla = obtener_ruido(num_imagenes_mostrar, z_dim, dispositivo = dispositivo)\n",
        "    for generacion in range(generacion_actual,num_generaciones+1):\n",
        "      print('Generación:',generacion)\n",
        "      #Lista con las aptitudes de la generación\n",
        "      aptitudes_generacion = []\n",
        "      #Por partícula en el enjambre y por cada indice\n",
        "      for particula, num_particula in zip(enjambre, range(num_particulas)):\n",
        "       \n",
        "        print('Particula: ', num_particula+1)\n",
        "        print('Codificación: ', particula)\n",
        "        #Obtener el generador y el discriminador decodificando y entrenando la partícula\n",
        "        gen, disc = entrenar(particula, num_epocas, dataset)\n",
        "        #Evaluar la aptitud del generador\n",
        "        print('Evaluando aptitud de la partícula...')\n",
        "        aptitud = evaluar_aptitud(gen) #Evaluar el FID del generador\n",
        "        print('Aptitud de la partícula: ', aptitud)\n",
        "        aptitudes_generacion.append(aptitud) #Guardar la aptitud\n",
        "        #Mostrar un lote imágenes sintéticas\n",
        "        print('Lote de imágenes sintéticas:')\n",
        "        mostrar_imagen(gen(semilla), num_imagenes_mostrar)\n",
        "        print('')\n",
        "        #Si su valor de FID es mejor que el valor de su mejor solución encontrada entonces cambiarla\n",
        "        if aptitud < p_best_apt[num_particula]:\n",
        "          p_best_apt[num_particula] = aptitud\n",
        "          p_bests[num_particula] = particula\n",
        "          #Si el valor de la aptitud es mejor que el de la mejor partícula del enjambre, entonces se reemplaza\n",
        "          if aptitud < g_best_apt:\n",
        "            g_best_apt = aptitud\n",
        "            g_best = particula\n",
        "              \n",
        "\n",
        "    \n",
        "        \n",
        "\n",
        "      #Mostrar el mejor de la generación\n",
        "      print('Mejor en la generación: ', generacion)\n",
        "      print('Codificación de la mejor partícula: ', g_best)\n",
        "      print('Aptitud del mejor: ', g_best_apt)\n",
        "      print('Aptitudes de las mejores arquitecturas encontradas por cada partícula: ', p_best_apt)\n",
        "      print('')\n",
        "\n",
        "\n",
        "      #Se actualiza cada partícula del enjambre\n",
        "      for i in range(num_particulas):\n",
        "        enjambre[i] = actualizar_particula(g_best, p_bests[i], enjambre[i])\n",
        "      lista_aptitud_mejor.append(g_best_apt)\n",
        "      plt.figure(figsize=(7,8))\n",
        "      plt.plot(list(range(1,len(lista_aptitud_mejor)+1,1)),lista_aptitud_mejor,'o-')\n",
        "      plt.xticks(list(range(1,len(lista_aptitud_mejor)+1,1)))\n",
        "      plt.title('Mejor aptitud por generación', fontweight='bold')\n",
        "      plt.ylabel('FID', fontsize=16, fontweight='bold')\n",
        "      plt.xlabel('Generación', fontsize=16, fontweight='bold')\n",
        "      plt.xticks(fontsize=12)\n",
        "      plt.yticks(fontsize=12)\n",
        "      plt.show()\n",
        "      print('')\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MryEZxUYjgOm"
      },
      "source": [
        "#Semillas de aleatoriedad para garantizar resultados iguales para todos. \n",
        "#Estos valores también se pueden cambiar para experimentar\n",
        "torch.manual_seed(9) \n",
        "np.random.seed(26)\n",
        "#Realizar el proceso de evolución\n",
        "evolucionar(num_particulas, num_generaciones, num_epocas, dataloader, resolucion_actual, num_imagenes_mostrar=25, inicio = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}